<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Norm Matloff">

<title>All of REAL Statistics – fastStat</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-79108a0fc1995748cbd19a5b0e3e3e7c.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body>

<div id="quarto-search-results"></div>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#who-is-this-for" id="toc-who-is-this-for" class="nav-link active" data-scroll-target="#who-is-this-for">WHO IS THIS FOR?</a></li>
  <li><a href="#what-is-really-going-on-in-statistics" id="toc-what-is-really-going-on-in-statistics" class="nav-link" data-scroll-target="#what-is-really-going-on-in-statistics">What Is Really Going on in Statistics?</a></li>
  <li><a href="#lesson-sampling-the-notion-of-a-sample" id="toc-lesson-sampling-the-notion-of-a-sample" class="nav-link" data-scroll-target="#lesson-sampling-the-notion-of-a-sample">Lesson SAMPLING: the Notion of a Sample</a></li>
  <li><a href="#lesson-normaletc-the-role-of-normal-gaussian-and-other-parametric-distribution-families" id="toc-lesson-normaletc-the-role-of-normal-gaussian-and-other-parametric-distribution-families" class="nav-link" data-scroll-target="#lesson-normaletc-the-role-of-normal-gaussian-and-other-parametric-distribution-families">Lesson NORMALETC: the Role of Normal (Gaussian) and Other Parametric Distribution Families</a></li>
  <li><a href="#lesson-conceptpops-conceptual-populations" id="toc-lesson-conceptpops-conceptual-populations" class="nav-link" data-scroll-target="#lesson-conceptpops-conceptual-populations">Lesson CONCEPTPOPS: Conceptual Populations</a></li>
  <li><a href="#lesson-stderrs-standard-errors" id="toc-lesson-stderrs-standard-errors" class="nav-link" data-scroll-target="#lesson-stderrs-standard-errors">Lesson STDERRS: Standard Errors</a></li>
  <li><a href="#lesson-bias-bias-and-impact-on-standard-errors" id="toc-lesson-bias-bias-and-impact-on-standard-errors" class="nav-link" data-scroll-target="#lesson-bias-bias-and-impact-on-standard-errors">Lesson BIAS: Bias, and Impact on Standard Errors</a></li>
  <li><a href="#lesson-ci-confidence-intervals" id="toc-lesson-ci-confidence-intervals" class="nav-link" data-scroll-target="#lesson-ci-confidence-intervals">Lesson CI: Confidence Intervals</a></li>
  <li><a href="#lesson-ciapprox-confidence-intervals-from-asymptotics" id="toc-lesson-ciapprox-confidence-intervals-from-asymptotics" class="nav-link" data-scroll-target="#lesson-ciapprox-confidence-intervals-from-asymptotics">Lesson CIAPPROX: Confidence Intervals from Asymptotics</a></li>
  <li><a href="#lesson-indicators-cis-from-indicator-variables" id="toc-lesson-indicators-cis-from-indicator-variables" class="nav-link" data-scroll-target="#lesson-indicators-cis-from-indicator-variables">Lesson INDICATORS: CIs from Indicator Variables</a></li>
  <li><a href="#lesson-geyser-old-faithful-geyser-example" id="toc-lesson-geyser-old-faithful-geyser-example" class="nav-link" data-scroll-target="#lesson-geyser-old-faithful-geyser-example">Lesson GEYSER: Old Faithful Geyser Example</a></li>
  <li><a href="#lesson-converge-more-on-asymptotics" id="toc-lesson-converge-more-on-asymptotics" class="nav-link" data-scroll-target="#lesson-converge-more-on-asymptotics">Lesson CONVERGE: More on Asymptotics</a></li>
  <li><a href="#lesson-somemath-some-derivations" id="toc-lesson-somemath-some-derivations" class="nav-link" data-scroll-target="#lesson-somemath-some-derivations">Lesson SOMEMATH: Some Derivations</a></li>
  <li><a href="#lesson-sig-significance-testing" id="toc-lesson-sig-significance-testing" class="nav-link" data-scroll-target="#lesson-sig-significance-testing">Lesson SIG: Significance Testing</a></li>
  <li><a href="#lesson-mlemm-general-methods-of-estimation" id="toc-lesson-mlemm-general-methods-of-estimation" class="nav-link" data-scroll-target="#lesson-mlemm-general-methods-of-estimation">Lesson MLEMM: General Methods of Estimation</a></li>
  <li><a href="#lesson-estdistrs-estimating-entire-distributions" id="toc-lesson-estdistrs-estimating-entire-distributions" class="nav-link" data-scroll-target="#lesson-estdistrs-estimating-entire-distributions">Lesson ESTDISTRS: estimating entire distributions</a></li>
  <li><a href="#lesson-dens1-estimating-probability-density-functionshistograms" id="toc-lesson-dens1-estimating-probability-density-functionshistograms" class="nav-link" data-scroll-target="#lesson-dens1-estimating-probability-density-functionshistograms">Lesson DENS1: estimating probability density functions–histograms</a></li>
  <li><a href="#lesson-trade-the-bias-variance-tradeoff" id="toc-lesson-trade-the-bias-variance-tradeoff" class="nav-link" data-scroll-target="#lesson-trade-the-bias-variance-tradeoff">Lesson TRADE: the Bias-Variance Tradeoff</a></li>
  <li><a href="#lesson-multi-multivariate-distributions" id="toc-lesson-multi-multivariate-distributions" class="nav-link" data-scroll-target="#lesson-multi-multivariate-distributions">Lesson MULTI: Multivariate Distributions</a></li>
  <li><a href="#lesson-corr-correlation" id="toc-lesson-corr-correlation" class="nav-link" data-scroll-target="#lesson-corr-correlation">Lesson CORR: Correlation</a></li>
  <li><a href="#lesson-mvn-the-multivariate-normal-distribution-family" id="toc-lesson-mvn-the-multivariate-normal-distribution-family" class="nav-link" data-scroll-target="#lesson-mvn-the-multivariate-normal-distribution-family">Lesson MVN: The Multivariate Normal Distribution Family</a></li>
  <li><a href="#lesson-predict-predictive-modeling-preliminaries" id="toc-lesson-predict-predictive-modeling-preliminaries" class="nav-link" data-scroll-target="#lesson-predict-predictive-modeling-preliminaries">Lesson PREDICT: Predictive Modeling – Preliminaries</a></li>
  <li><a href="#lesson-mlb-the-mlb-dataset" id="toc-lesson-mlb-the-mlb-dataset" class="nav-link" data-scroll-target="#lesson-mlb-the-mlb-dataset">Lesson MLB: the MLB Dataset</a></li>
  <li><a href="#lesson-lin-predictive-modeling-linear" id="toc-lesson-lin-predictive-modeling-linear" class="nav-link" data-scroll-target="#lesson-lin-predictive-modeling-linear">Lesson LIN: Predictive Modeling – Linear</a></li>
  <li><a href="#lesson-lmderive-the-math-behind-least-squares-estimation" id="toc-lesson-lmderive-the-math-behind-least-squares-estimation" class="nav-link" data-scroll-target="#lesson-lmderive-the-math-behind-least-squares-estimation">Lesson LMDERIVE: The math behind least-squares estimation</a></li>
  <li><a href="#lesson-logit-predictive-modeling-logistic" id="toc-lesson-logit-predictive-modeling-logistic" class="nav-link" data-scroll-target="#lesson-logit-predictive-modeling-logistic">Lesson LOGIT: Predictive Modeling – Logistic</a></li>
  <li><a href="#lesson-knn-predictive-modeling-k-nearest-neighbors" id="toc-lesson-knn-predictive-modeling-k-nearest-neighbors" class="nav-link" data-scroll-target="#lesson-knn-predictive-modeling-k-nearest-neighbors">Lesson KNN: Predictive Modeling – k-Nearest Neighbors</a></li>
  <li><a href="#lesson-tree-predictive-modeling-tree-based-algorithms" id="toc-lesson-tree-predictive-modeling-tree-based-algorithms" class="nav-link" data-scroll-target="#lesson-tree-predictive-modeling-tree-based-algorithms">Lesson TREE: Predictive Modeling – Tree-Based Algorithms</a></li>
  <li><a href="#lesson-svm-predictive-modeling-support-vector-machines" id="toc-lesson-svm-predictive-modeling-support-vector-machines" class="nav-link" data-scroll-target="#lesson-svm-predictive-modeling-support-vector-machines">Lesson SVM: Predictive Modeling – Support Vector Machines</a></li>
  <li><a href="#lesson-neural-predictive-modeling-neural-networks" id="toc-lesson-neural-predictive-modeling-neural-networks" class="nav-link" data-scroll-target="#lesson-neural-predictive-modeling-neural-networks">Lesson NEURAL: Predictive Modeling – Neural Networks</a></li>
  <li><a href="#lesson-nbhr-predictive-modeling-a-feature-neighborhood-view-of-overfitting-in-ml" id="toc-lesson-nbhr-predictive-modeling-a-feature-neighborhood-view-of-overfitting-in-ml" class="nav-link" data-scroll-target="#lesson-nbhr-predictive-modeling-a-feature-neighborhood-view-of-overfitting-in-ml">Lesson NBHR: Predictive Modeling – a Feature Neighborhood View of Overfitting in ML</a></li>
  <li><a href="#lesson-polyml-predictive-modeling-a-polynomial-view-of-overfitting-in-ml" id="toc-lesson-polyml-predictive-modeling-a-polynomial-view-of-overfitting-in-ml" class="nav-link" data-scroll-target="#lesson-polyml-predictive-modeling-a-polynomial-view-of-overfitting-in-ml">Lesson POLYML: Predictive Modeling – a Polynomial View of Overfitting in ML</a></li>
  <li><a href="#lesson-over-predictive-modeling-avoiding-overfitting" id="toc-lesson-over-predictive-modeling-avoiding-overfitting" class="nav-link" data-scroll-target="#lesson-over-predictive-modeling-avoiding-overfitting">Lesson OVER: Predictive Modeling – Avoiding Overfitting</a></li>
  <li><a href="#lesson-noworry-predictive-modeling-ignoring-overfitting" id="toc-lesson-noworry-predictive-modeling-ignoring-overfitting" class="nav-link" data-scroll-target="#lesson-noworry-predictive-modeling-ignoring-overfitting">Lesson NOWORRY: Predictive Modeling – Ignoring Overfitting</a></li>
  <li><a href="#lesson-privacy-data-privacy" id="toc-lesson-privacy-data-privacy" class="nav-link" data-scroll-target="#lesson-privacy-data-privacy">Lesson PRIVACY: Data Privacy</a></li>
  <li><a href="#licensing" id="toc-licensing" class="nav-link" data-scroll-target="#licensing">LICENSING</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">All of REAL Statistics</h1>
<p class="subtitle lead">Fast Track to Stat for Those with Probabilty Background</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Norm Matloff </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<p><a href="https://heather.cs.ucdavis.edu/matloff.html">Author bio</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Rho2-1.png" class="img-fluid figure-img" width="300"></p>
<figcaption>3D Bell Density</figcaption>
</figure>
</div>
<p>(Above image source unknown. See notice at the end of this document regarding copyright of the document.)</p>
<section id="who-is-this-for" class="level1">
<h1>WHO IS THIS FOR?</h1>
<p>Students in computer science, engineering, mathematics and the like typically take a course in calculus-based probability – unconditional and conditional probability, cdfs and density functions, expected value and so on. (The material is in Chapters 1-9 of <a href="https://github.com/matloff/probstatbook">my online book</a>.) But later they have a need to use statistics, and find it’s a broader and more nuanced field than they had realized.</p>
<p><strong>This document will enable such people to quickly acquire the needed concepts, with a good intuitive understanding.</strong> It is modeled after my popular <a href="https://github.com/matloff/fasteR">fasteR tutorial</a> for quickly becoming proficient in R.</p>
<p>By the way, the title, “All of REAL Statistics,” is a play on the titles of two excellent books, <em>All of Statistics</em> and <em>All of Nonparametric Statistics</em>, by one of my favorite statisticians, Larry Wasserman. Both books are quite thin, making their “All of” titles ironic. Well, my short tutorial here is even more “all of” in that sense.</p>
</section>
<section id="what-is-really-going-on-in-statistics" class="level1">
<h1>What Is Really Going on in Statistics?</h1>
<p>Professional statisticians, especially Statistics professors, may find the presentation here to be a familiar story – but with an odd plot, a different cast of characters, and a different ending. :-) It will be the standard material, but viewed a broader contexts, especially real world practice.</p>
<p>Indeed, <strong>many of readers of this tutorial will be surprised to see that it does not contain many equations.</strong> But sadly, many people know the mechanics of statistics very well, without truly understanding on intuitive levels what those equations are really doing, and this is our focus.</p>
<p>For instance, consider estimator bias. Students in a math stat course learn the mathematical definition of bias, after which they learn that the sample mean is unbiased and that the sample variance can be adjusted to be unbiased. But that is the last they hear of the issue. Actually, most estimators are in fact biased, and lack “fixes” like that of the sample variance. Does it matter? None of that is discussed in textbooks and courses.</p>
<p>We will indeed do some math derivations here, but not at the outset, and not highlighted. This tutorial aims to explain the practical ISSUES. Many of these are rather generally known, but not written down in books. Some are actually not widely known. And some are entirely new ways of looking at familiar statistical concepts and properties.</p>
</section>
<section id="lesson-sampling-the-notion-of-a-sample" class="level1 page-columns page-full">
<h1>Lesson SAMPLING: the Notion of a Sample</h1>
<p>We’ve all heard the term <em>margin of error</em> in an opinion poll. It will be discussed in detail in a later lesson, but what question is it addressing?</p>
<p>Say the poll consists of querying 1200 people, which is common in polls. These were drawn randomly from some list, say a list of phone numbers. We ask each one, “Do you favor Candidate A?” The point is that if we were to do this again, we would get 1200 other people, and the percentage saying Yes to our question would change. Thus we want to have some idea as to how much our Yes percentage varies from one sample of 1200 people to another.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">Sampling 1200 people is not referred to as “1200 samples.” The set of 1200 people is referred to as one sample of size 1200.</span></div></div>
<p>Let’s set some notation. Say we are interested in some quantity X, say human height. We take a sample of n people from a given target population, and denote the value of X in the i<sup>th</sup> person in our sample by X<sub>i</sub>. If we sample with replacement (or if n is small relative to the total population size), the X<sub>i</sub> are independent random variables. Also, each X<sub>i</sub> has distribution equal to that of the sampled population. If, say 22.8% of people in this population are taller than 70 inches, then P(X<sub>i</sub> &gt; 70) = 0.228.</p>
<p>So, X<sub>1</sub>,…,X<sub>n</sub> are independent, identically distributed random variables (iid).</p>
</section>
<section id="lesson-normaletc-the-role-of-normal-gaussian-and-other-parametric-distribution-families" class="level1">
<h1>Lesson NORMALETC: the Role of Normal (Gaussian) and Other Parametric Distribution Families</h1>
<p>In the last lesson, we talked about the distribution of X in the population. Although the population is finite (more on this below) and thus X is a discrete random variable, one often models X as continuous, with its distribution being in the normal family.</p>
<p>Why do this?</p>
<ul>
<li><p>Histograms of X in many applications do look rather bell-shaped. This may in turn be due to the Central Limit Theorem (CLT). The CLT says that sums are approximately normal, and in the human height case, one can think of the body as consisting of chunks whose heights sum to the height of the person. (The CLT assumes i.i.d. summands, and the chunks here would be neither independent nor indentically distributed, but there are non-i.i.d. versions of the CLT.)</p></li>
<li><p>The early developers of statistics had no computers, and it turns out that the normal distribution family is quite mathematically tractable, thus amenable to closed-form “exact” solutions.</p></li>
<li><p>It is often the case in math that discrete quantities are approximated by continuous ones (also vice versa).</p></li>
<li><p>A normal distribution is determined by two parameters, the mean and variance of the distribution. Without that assumption, we have many parameters, essentially infinitely many. Let F<sub>x</sub> be the cdf of X, i.e.&nbsp;F<sub>X</sub>(t) = P(X ≤ t). Well, there are infinitely many possible values for t, thus infinitely many values of F<sub>X</sub>(t). But if we assume X is normal, those infinitely many values are all expressible in terms of just two numbers. We are then essentially estimating two numbers instead of infinitely many. This is often a very useful approximation.</p></li>
</ul>
<p>Another popular model is the exponential distribution family. You probably learned in your probability course that it is “memoryless,” which makes it a suitable model in some applications.</p>
<p>Note that, as models, these are necessarily inexact. No distribution in practice is exactly normal, for instance. No one is 900 feet tall, and no one has a negative height. For that matter, a normal distribution is continuous, whereas X is discrete, for two reasons:</p>
<ul>
<li><p>We are sampling from a finite population.</p></li>
<li><p>Our measuring instruments have only finite precision. If, say, X is bounded between 0 and 10, and is measured to 2 decimal places, X can take on 1000 values, and thus is discrete.</p></li>
</ul>
<p>But what are we estimating, in light of the fact that our model is only approximate? Say for instance we model X as having a gamma distribution. Then in some sense, depending on how we estimate, we are estimating the gamma distribution that is closest to our true population distribution.</p>
</section>
<section id="lesson-conceptpops-conceptual-populations" class="level1">
<h1>Lesson CONCEPTPOPS: Conceptual Populations</h1>
<p>In the opinion poll example, it is clear as to which population is sampled. In many applications, the issue is more conceptual. If for instance we run a clinical trial with 100 diabetic patients, we might think of them as having been sampled from the population of all diabetics, even though we did not actually select the patients in our sample, whether randomly or otherwise.</p>
<p>This issue can become quite a challenge in, say, economic analysis. If we have 10 years of annual data, i.e.&nbsp;n = 10, what population is that a “sample” from?</p>
<p>Accordingly, in many applications, the population we model as being sampled from is largely conceptual rather than a tangible entity.</p>
<p>Say we have 1200 patients in a clinical trial of a drug for treating hypertension. Then our sample might be considered as a random sample of the population of all sufferers of hypertension, but this may be an oversimplification. Serious consideration should be given to the implications of our sampling method on the definition of the sampled population.</p>
</section>
<section id="lesson-stderrs-standard-errors" class="level1 page-columns page-full">
<h1>Lesson STDERRS: Standard Errors</h1>
<p>Earlier we mentioned the “margin of error” in reporting the results of opinion polls. To make that notion concrete, let’s first discuss a related idea, <em>standard errors</em>.</p>
<p>We use our data X<sub>1</sub>,…,X<sub>n</sub> to estimate some quantity of interest, say the proportion q of people in the population who would answer Yes to our poll if we had a chance to ask them all. Our estimate, Q, would be the proportion of people in our sample who say Yes.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class=""><strong>Extremely important note:</strong> Make sure to always carefully distinguish between a population quantity, q in this case, and its sample estimate, Q here.</span></div></div>
<p>We want to have some measure of how much Q varies from one sample to another. Of course, Var(Q) is such a measure.</p>
<p>Say for now that the average of Q, averaged over all possible samples, is q. For some samples, Q &gt; q, for others Q &lt;- q, but on average we get q. This relates to the issue of <em>bias</em>, which we will turn to later, but for now, say we have this situation, i.e.&nbsp;EQ = q.</p>
<p><strong>The key point:</strong> If Var(Q) is small, then Q doesn’t vary much from one sample to another, and if EQ = q, then for “most” samples, Q should be near q. That is exactly what we hope for! We only have one sample, of course, but if we know that Q is usually near q, we feel reasonably confident that the q from our particular sample is near q.</p>
<p>Of course, the square root of any variance is called the <em>standard deviation</em>. In the case of an estimator, Q here, we use the term <em>standard error</em>. In some cases, it will be only the approximate standard deviation, in a sense to be seen later.</p>
</section>
<section id="lesson-bias-bias-and-impact-on-standard-errors" class="level1 page-columns page-full">
<h1>Lesson BIAS: Bias, and Impact on Standard Errors</h1>
<p>In our last lesson, we assumed that EQ = q. We say that Q is an <em>unbiased</em> estimator of q. In English: The average value of Q over all possible samples is q.</p>
<div class="page-columns page-full"><p>In the above example, in which Q is the sample proportion of Yes’s and q is the correspondng population proportion, it does turn out that Q is unbiased. In fact, any sample mean is an unbiased estimator for the population mean.  Let’s skip the derivation for now (we’ll have a derivations lesson later), so we can get to the larger issues.</p><div class="no-row-height column-margin column-container"><span class="">Here X is 1 or 0, with 1 meaning the respondent answered Yes, and 0 meaning No.&nbsp;So the average of the X<sub>i</sub>, Q, is the proportion of voters choosing Candidate A.</span></div></div>
<p>Unbiasedness at first seems to be a very desirable property. It does hold for some classical statistical methods, but does not hold for most others, one of which is the sample variance, as follows.</p>
<p>Say we wish to estimate the population variance σ<sup>2</sup>. Note that</p>
<p><span class="math display">\[
Var(X_{i}) = \sigma^2
\]</span></p>
<p>And recall that also</p>
<p><span class="math display">\[
EX_{i} = \mu
\]</span></p>
<p>the population mean. Note too that we are not necessarily assuming a normal distribution.</p>
<p>In the population, that is the average squared difference between the data and their mean. The sample analog is</p>
<p><span class="math display">\[
S^{2} = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2
\]</span></p>
<p>where <span class="math inline">\(\bar{X}\)</span> is the sample mean,</p>
<p><span class="math display">\[
\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i
\]</span></p>
<p>Note especially the word <em>analog</em> above. Here is the analogy:</p>
<ul>
<li>σ<sup>2</sup> is the average squared distance of X, in the population, to the population mean:</li>
</ul>
<p><span class="math display">\[
\sigma^2 = E[(X - \mu)^2]
\]</span></p>
<ul>
<li>S<sup>2</sup> is the average squared distance of X, in the sample, to the sample mean.</li>
</ul>
<p>It can be shown that S<sup>2</sup> is biased downward:</p>
<p>E(S<sup>2</sup>) = [(n-1) / n] σ<sup>2</sup></p>
<p>The average value of S<sup>2</sup> over all samples is a little too low. The amount of bias is</p>
<p>E(S<sup>2</sup>) - σ<sup>2</sup> = -1/n σ<sup>2</sup></p>
<p>This is usually tiny, but it bothered the early developers of statistics, who then adjusted the definition of sample variance to</p>
<p><span class="math display">\[
s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2
\]</span></p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">By the way, in the field of probability and statistics, it is customary to use capital letters for random variables. This is an exception.</span></div></div>
<p>Note our distinction between S<sup>2</sup> and the similar but slightly different quantity, <span class="math inline">\(s^2\)</span>. Both are random variables – they depend on the X<sub>i</sub>, which are random – but they are different random variables. Typographical case matters.</p>
<p>Since for any random variable W (for which EW exists) and any constant c we have E(cW) = c EW, s<sup>2</sup> is now unbiased.</p>
<p>The variance of <span class="math inline">\(\bar{X}\)</span> turns out to be <span class="math inline">\(\sigma^2/n\)</span>. But we don’t know <span class="math inline">\(\sigma^2\)</span>, just like we don’t know <span class="math inline">\(\mu\)</span>. So we estimate <span class="math inline">\(\sigma\)</span> by S or s. So, we set</p>
<p><span class="math display">\[
s.e.(\bar{X}) = S / \sqrt{n}
\]</span></p>
<p>(use s instead of S if you wish; it won’t matter below).</p>
<p>But most estimators are not only biased, but also lack simple adjustments like that for S<sup>2</sup> above. So, one must accept bias in general, and consider its implications.</p>
<p>Now, should we use S or s? Say an estimator has variance of size <span class="math inline">\(O(\frac{1}{n})\)</span>, as above. Yet the difference in expected values of S and s is of size <span class="math inline">\(O(\frac{1}{n^2})\)</span>. In other words, it really doesn’t matter whether we use S or s for larger samples; the bias is small relative to the standard error, so the argument in the last lesson still holds.</p>
</section>
<section id="lesson-ci-confidence-intervals" class="level1">
<h1>Lesson CI: Confidence Intervals</h1>
<p>In our opinion poll example, Q is called a <em>point estimate</em> of q. We would also like to have an <em>interval estimate</em>, which gives a range of values. If say in in an election, the results of an opinion poll are reported as, “Candidate X has support of 62.1% of the voters, with a margin of error of 3.9%,” it is saying,</p>
<blockquote class="blockquote">
<p>A 95% confidence interval (CI) for X’s support is (58.2%,66.0%).</p>
</blockquote>
<p>We will show below that the radius of a 95% CI is 1.96 times the standard error of the given estimator Q. By the way, most CIs in this document will be only approximate, a point to be discussed shortly.</p>
<p>A key point is the meaning of “95% confident.” Imagine forming this interval on each possible sample from the given population. Then 95% of the intervals would cover the true value, q.</p>
<p>A note on the phrasing “q is in our interval”:</p>
<blockquote class="blockquote">
<p>Some may take this to mean that q is random, which it is not; q is unknown but fixed. The CI is what varies from one sample to another. Some instructors are so worried about such misinterpreation that they ban the phrasing “q is in the CI,” insisting that students say “The CI <em>contains</em> q, to emphasize that the CI is random, not q. To me, that’s going to absurd lengths to make a point – the two statements are linquistically equivalent, after all – but again, these instructors feel that misintepretation is less likely this way.</p>
</blockquote>
<p>A related, and much deeper, philosophical question is whether it is correct to say, “The probability that q is in <em>this</em> CI is 0.95.” Most statisticians would say that tnis too is an incorrect. They say it violates the view that the 95% figure can only be applied in the “repeated sampling” context. To them, the probability that q is in <em>this</em> CI is either 0 or 1.</p>
<p>But really, what do we mean by probability? It depends on the context. Consider the famous <a href="https://heather.cs.ucdavis.edu/ProbStatDSBook/MontyHall.pdf">Monty Hall game show problem.</a> To the host, the probability is 1 that the car is behnd door 3. But to the contestant, that probability is 2/3. In the CI situation, “Nature” knows whether this CI contains q; to us, the probability is 0.95.</p>
</section>
<section id="lesson-ciapprox-confidence-intervals-from-asymptotics" class="level1 page-columns page-full">
<h1>Lesson CIAPPROX: Confidence Intervals from Asymptotics</h1>
<p>The early developers of statistics defined a distribution family known as <em>Student’s t</em>. This supposedly can be used to form “exact” CIs, i.e.&nbsp;the probability of the CI covering the target population value is exactly 0.95, if the population distribution of X is normal. Student-t is widely taught, and thus widely used. <strong>BUT it is just an illusion.</strong> As pointed out earlier, no distribution in practice is exactly normal.</p>
<p>What saves the day, though, is the Central Limit Theorem. <span class="math inline">\(\bar{X}\)</span> is a (scaled) sum, which the CLT tells us is asymptotically normally distributed as the sample size n goes to infinity.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">Technically, the CLT is phrased only in terms of cumulative distribution functions, not probability density functions. So this comment on a histogram doesn’t follow from the CLT, but “the probabilities for any range of values” does follow from it.j More on this below, but note that there is also the <em>Local Limit Theorem</em> for density convergence, and in practice, the density functions converge too.</span></div></div>
<p>In other words, if we were to compute <span class="math inline">\(\bar{X}\)</span> on each of the possible samples of size n from the population, and then plot the results in a histogram, the graph would be approximately bell-shaped, and the probabilities for any range of values would be approximately those of a normal distribution. Moreover, the large n, the more bell-shaped it would be.</p>
<p>Ah, so we’re in business: For any random variable W, the quantity</p>
<p>(W - EW) / (Var(W)<sup>0.5</sup>)</p>
<p>has mean 0 and variance 1. (This stems simply from the properties of mean and variance; it has nothing to do with whether W is normal or not.) So,</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \mu}{\frac{\sigma}{\sqrt{n}}}
\]</span></p>
<p>has mean 0 and variance 1, where μ is the population mean of X. (Recall that <span class="math inline">\(\bar{X}\)</span> is unbiased for <span class="math inline">\(\mu\)</span>.)</p>
<p>And since Z actually does have an approximately normal distribution, its distribution is thus approximately N(0,1), i.e.&nbsp;normal with mean 0 and variance 1. Replacing σ, which is unknown. by its estimate s can be further justified mathematically, so let’s redefine Z as</p>
<p><span class="math display">\[
Z = \frac{\bar{X} - \mu}{\frac{s}{\sqrt{n}}}
\]</span></p>
<p>which is approximately N(0,1), and this is what we exploit to form a CI, as folows.</p>
<p>The N(0,1) distribution has 95% of its area between -1.96 and 1.96: e.g.&nbsp;run</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.025</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>So we have</p>
<p><span class="math display">\[
0.95 \approx P(-1.96 &lt; \frac{\bar{X} - \mu}{s/\sqrt{n}} &lt; 1.96)
\]</span></p>
<p>which after algebra becomes</p>
<p><span class="math display">\[
0.95 \approx P[\bar{X} - 1.96 ~ s.e.(\bar{X}) &lt; \mu &lt;
\bar{X} + 1.96 ~ s.e.(\bar{X})]
\]</span></p>
<p>There’s our CI for μ!</p>
<p><span class="math display">\[
(\bar{X} - 1.96 ~ s.e.(\bar{X}),
\bar{X} + 1.96 ~ s.e.(\bar{X}))
\]</span></p>
<p>We are (approximately) 95% confident that the true population mean is in that interval. (Remember. it is the interval that is random, not μ.)</p>
<p>And things don’t stop there. Actually, many types of estimators have some kinds of sums within them, and thus have an approximately normal distribution, provided the estimator is a smooth function of those sums.</p>
<p>(<em>Smooth</em> here means a smooth curve, no sharp corners, thus having a derivative. A Taylor series approximation results in a linear function of normal random variable, thus again normal.)</p>
<p>Thus approximate CIs can be found for lots of different estimators, notably Maximum Likelihood Estimators and least-squares parametric regression estimators, as we will see in later lessons.</p>
<p>In other words, we have the following principle:</p>
<p><strong>The Fundamental Tool of Statistical Inference:</strong></p>
<p>(The name here is my own, not a general term, but the principle is widely used.)</p>
<blockquote class="blockquote">
<p>If R is a “smooth” estimator of a population quantity r, and R consists of sums, based on an i.i.d. sample, then an approximate 95% confidence interval for r is</p>
<p>(R - 1.96 s.e.(R), R + 1.96 s.e.(R))</p>
</blockquote>
<p>Again, the term <em>smooth</em> roughly means that R is a differentiable function of X<sub>1</sub>, …, X<sub>n</sub>.</p>
<p>By the way, for large n, the Student-t distribution is almost identical to N(0,1), so “no harm, no foul” – Student-t will be approximately correct. But it won’t be exactly correct, in spite of the claim.</p>
</section>
<section id="lesson-indicators-cis-from-indicator-variables" class="level1">
<h1>Lesson INDICATORS: CIs from Indicator Variables</h1>
<p>Often X has only the values only 1 and 0, indicating the presence or absence of some trait. That is the case in the opinion poll, for example, where the respondent replies Yes (1) or not-Yes (0). Such a variable is called an <em>indicator variable</em>, as it indicates whether the trait is present or not. It is also called <em>dummy variable</em> and in the case of machine learning people, a <em>one-hot variable</em>.</p>
<p>In this case, Ā is the average of a bunch of 0s and 1s. The sum of such numbers will be the number of 1s, so Ā reduces to the proportion of 1s. The quantity μ is then the population proportion P(X = 1).</p>
<p>In the election poll example, Ā is then Q, the proportion of Yes responses to the opinion poll, with q being the corresponding population proportion.</p>
<p>After some algebraic simplification, it turns out that</p>
<p>S<sup>2</sup> = Ā (1-Ā) / n</p>
<p>(or use n-1 instead of n for s).</p>
<p>Our earlier CI for a population mean now becomes in this special case</p>
<p>(Ā - 1.96 sqrt[ Ā (1-Ā) / n], Ā + 1.96 sqrt[ Ā (1-Ā) / n])</p>
</section>
<section id="lesson-geyser-old-faithful-geyser-example" class="level1">
<h1>Lesson GEYSER: Old Faithful Geyser Example</h1>
<p>To start to make the concepts tangible, let’s look at <strong>faithful</strong>, a built-in dataset in R, recording eruptions of the Old Faithful Geyser in the US National Park, Yellowstone.</p>
<p>The object consists of an R data frame with 2 columns, <strong>eruptions</strong> and <strong>waiting</strong>, showing the eruption durations and times between eruptions. the conceptual “population” here is the set of all Old Faithful eruptions, past, present and future.</p>
<p>Let’s start simple, with a CI for the population mean duration:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>erps <span class="ot">&lt;-</span> faithful<span class="sc">$</span>eruptions</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>samplemean <span class="ot">&lt;-</span> <span class="fu">mean</span>(erps)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>s2 <span class="ot">&lt;-</span> <span class="fu">var</span>(erps)  <span class="co"># this is s^2 not S^2</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>stderr <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(s2<span class="sc">/</span><span class="fu">length</span>(erps))</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(samplemean <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span>stderr, samplemean <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span>stderr)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># (3.35,3.62)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="lesson-converge-more-on-asymptotics" class="level1">
<h1>Lesson CONVERGE: More on Asymptotics</h1>
<p>The concept of standard error needs to be clarified.</p>
<p>What does the CLT say, exactly? The formal statement is</p>
<blockquote class="blockquote">
<p>Say S<sub>n</sub> is the sum of iid random variables, each with mean μ and variance σ<sup>2</sup>. Then</p>
<p>Z<sub>n</sub> = (S<sub>n</sub> - μ) / [σ sqrt(n)]</p>
<p><em>converges in distribution</em> to N(0,1), <strong>meaning that</strong> the cdf of Z<sub>n</sub> converges to the N(0,1) cdf.</p>
</blockquote>
<p>In other words, the asymptotics apply to probabilities–but not to expected values etc. Two random variables can have almost the same cdf but have very different means, variances and so on. E.g. take any random variable and shift a small amount of its probability mass from X = c to some huge number X = d; almost the same cdf, very different mean.</p>
<p>As noted, if a sum is an ingredient in some complicated function that produces our estimator, we can apply a Taylor series argument to say that the estimator is asymptotically normal. But the standard deviation of that normal distribution may be different from that of the estimator itself, due to the inaccuracy of the Taylor approximation.</p>
<p>So, the asymptotic statement about regarding R and r above enables us to compute asymptotically valid CIs based on the N(0,1) cdf. But the standard error used in that interval, s.e.(R), is not necessarily the standard deviation of R.</p>
</section>
<section id="lesson-somemath-some-derivations" class="level1">
<h1>Lesson SOMEMATH: Some Derivations</h1>
<p>As noted earlier, the goal of this tutorial is to develop within the reader an understanding of the intuition underlying statistical concepts or methods. It is not a tutorial on math stat. Nevertheless, it’s important to show a few derivations.</p>
<p><strong>Ā is an unbiased estimator of μ:</strong></p>
<p>By the linearity of E(),</p>
<p>EĀ = (1/n) Σ<sub>i</sub><sup>n</sup> Ex<sub>i</sub> = (1/n) n μ = μ</p>
<p><strong>Var(Ā) = (1/n) σ<sup>2</sup>, where σ<sup>2</sup> is the population variance of X</strong></p>
<p>By the fact that the variance of a sum of independent random variables is the sum of their variances,</p>
<p>Var(Ā) = (1/n<sup>2</sup>) Σ<sub>i</sub><sup>n</sup> Var(x<sub>i</sub>) = (1/n<sup>2</sup>) n σ<sup>2</sup> = (1/n) σ<sup>2</sup></p>
<p><strong>S<sup>2</sup> is a biased estimator of σ<sup>2</sup></strong></p>
<p>For any random variable W (with finite variance),</p>
<p>Var(W) = E(W<sup>2</sup>) - (EW)<sup>2</sup></p>
<p>We will use this fact multiple times.</p>
<p>And the sample analog (just algebraic manipulation) is</p>
<p>S<sup>2</sup> = (1/n) Σ<sub>i</sub><sup>n</sup> X<sub>i</sub><sup>2</sup> - Ā<sup>2</sup></p>
<p>Applying E() to both sides of this last equation, we have</p>
<p>E(S<sup>2</sup>) = (1/n) n E(X<sup>2</sup>) - (Var(Ā) + μ<sup>2</sup>) = (σ<sup>2</sup> + μ<sup>2</sup>) - [(1/n) σ<sup>2</sup> + μ<sup>2</sup>] = [(n-1)/n] σ<sup>2</sup></p>
</section>
<section id="lesson-sig-significance-testing" class="level1">
<h1>Lesson SIG: Significance Testing</h1>
<p>The notion of <em>signficance testing</em> (ST) (also known as <em>hypothesis testing</em>, and <em>p-values</em>) is one of the real oddities in statistics.</p>
<ul>
<li><p>On the one hand, statisticians are well aware of the fact that ST can be highly miseadling.</p></li>
<li><p>But on the other hand, they teach ST with little or no warning about its dangers. As a result, its use is widespread–or more accurately stated, entrenched.</p></li>
</ul>
<p>As mentioned, the problems of ST have always been well-known, but nothing was done about them. Finally, in 2016, the American Statistical Association released its first-ever position paper on any topic, stating what everyone had known for decades: ST is just not a good tool.</p>
<p>To be sure, the ASA stopped short of recommending fully against ST, as some on the committee were defenders of it to some extent. The final statement did vaguely say ST is useful in some settings. But they gave no examples of this, and at the very least agreed that ST is indeed widely misused. But it is my position that ST should simply not be used at all. Instead, analysis should be based on CIs, as explained later in this lesson.</p>
<p>But first, what is ST? To keep things simple, let’s say we have some coin, and want to test the null hypothesis H<sub>0</sub>: r = 0.5, where r is the probability of heads. We will toss the coin n times, and set R to the proportion of heads in our sample.</p>
<p>We take an “innocent until proven guilty” approach, clinging to our belief in H<sub>0</sub> until/unless we see very strong evidence to the contrary. Well, what constitutes “strong”?</p>
<p>We look at the ratio W = (R-0.5) / s.e.(R). R is approximately normal, as noted earlier, and under H<sub>0</sub> R has mean 0. So under H<sub>0</sub>, W ~ N(0,1). (Tilde is standard notation for “distributed as.”) Then P(|W| &gt; 1.96) ≈ 0.05 and 5% is the traditional standard for “strong evidence.” We reject H<sub>0</sub> if and only if |W| &gt; 1.96.</p>
<p>And we can get greedy. What if, say, we find that R = 2.2? Note:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">pnorm</span>(<span class="sc">-</span><span class="fl">2.2</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.01390345</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Under H<sub>0</sub>, P(|W| &gt; 2.2) ≈ 0.028. Ah, we would have rejected H<sub>0</sub> even under the more stringent “strong evidence” criterion of 0.028. So we report 0.028, known as the <em>p-value</em>. The smaller the p-value, the more <em>signficant</em> we declare our finding.</p>
<p>Well, what’s wrong with that?</p>
<ul>
<li><p>We know <em>a priori</em> that H<sub>0</sub> is false. No coin is exactly balanced. So it’s rather silly to ask the question regarding H<sub>0</sub>.</p></li>
<li><p>We might be interested in knowing whether the coin is <em>approximately</em> balanced. Fine, but the ST is not addressing that question. Even if r is just a little different from 0, then as the number of tosses n goes to infinity, the denominator in W goes to 0, and thus R goes to ±∞–and the p-value goes to 0.</p></li>
<li><p>In such a scenario, we declare that the coin is “signficantly” unbalanced (“Look, a tiny p-value!”), an egregiously misleading statement.</p></li>
<li><p>We have the opposite problem with small n.&nbsp;We will declare “No signficant difference” when we actually should say, “We have too little data to make any claims.”</p></li>
</ul>
<p>One reason that ST is so appealing is that <strong>it allows the user to be lazy.</strong> Say we have two drugs, an old one A and a new one B, for treating high blood pressure. The user here may be a government agency, deciding whether to approve the new drug.</p>
<p>Let μ<sub>a</sub> and μ<sub>b</sub> denote the population mean effects of the two drugs. Then the null hypothesis is</p>
<p>H<sub>0</sub>: μ<sub>a</sub> = μ<sub>b</sub></p>
<p>Again, we know <em>a priori</em> that H<sub>0</sub> must be false–the two means can’t be equal, to infinitely many decimal places–so the test is meaningless in the first place, and we will have the problems described above. But, forget all that–the test gives us an answer, and the user is happy.</p>
<p>A more careful analysis would be based on forming a CI for the difference μ<sub>a</sub> - μ<sub>b</sub>. That gives us a range of values, against which we can weigh things like cost differences between the two drugs, possible side effects and so on. In addition, the width of the interval gives the user an idea as to whether there is enough data for accurate estimation of the means.</p>
<p>Yes, the user does have to make a decision, but it is an informed decision. In other words:</p>
<blockquote class="blockquote">
<p>The user is taking responsibility, making an informed decision, instead of allowing a poor statistical procedure to make the decision for him/her.</p>
</blockquote>
<p>Note by the way that what we are NOT doing is “check to see whether the CI contains 0,” which would have all the problems cited above.</p>
<p>See <a href="https://github.com/matloff/regtools/blob/master/inst/nopvals.md">this document</a> for further details.</p>
</section>
<section id="lesson-mlemm-general-methods-of-estimation" class="level1">
<h1>Lesson MLEMM: General Methods of Estimation</h1>
<p>So far, we’ve discussed only ad hoc estimators, set up for a specific purpose, such as S<sup>2</sup> for σ<sup>2</sup>. It would be nice to have general ways of forming estimators.</p>
<p>Note that our context here is that of <em>parametric distribution models</em>. Say for instance we are using an exponential model, in which the density of the random variable under consideration is</p>
<p>λ e<sup>-λ t</sup>, t &gt; 0</p>
<p>How can we estimate λ from our data?</p>
<p>The two most common such techniques are <em>Maximum Likelihood Estimators</em> (MLE) and the <em>Method of Moments Estimators</em> (MME). Let’s illustrate them with a simple example, MME first.</p>
<p><strong>The Method of Moments</strong></p>
<blockquote class="blockquote">
<p>Say we are estimating some parameter θ with the estimator (to be derived) named T. Then, in the formal expression for EX, replace θ by T; set the result to the sample mean Ā and solve for T.</p>
</blockquote>
<p>Say we are modeling our data X<sub>i</sub> as coming from a population with an exponential distribution, i.e.</p>
<p>f<sub>X</sub>(t) = λe<sup>-λt</sup>, t &gt; 0</p>
<p>It is well known (and easy to derive) that EX = 1 / λ. Denote our estimator of λ by L. Then the above recipe gives us</p>
<p>1 / L = Ā</p>
<p>and thus</p>
<p>L = 1 / Ā</p>
<p>It may be that our parametric model has 2 parameters rather than 1, so now θ = (θ<sub>1</sub>,θ<sub>2</sub>) and t = (t<sub>1</sub>,t<sub>2</sub>). Then in addition to generating an equation for the sample mean as above, we also generate a second equation for the sample variance in terms of the θ<sub>i</sub>; we replace the θ<sub>i</sub> by t<sub>i</sub>; on the right-hand side, we write the sample variance. That gives us 2 equations in 2 unknowns, and we solve for the t<sub>i</sub>.</p>
<p>For instance, say we wish to estimate the parameters λ and c for a gamma distribution. One can show that</p>
<p>EX = c/λ</p>
<p>and</p>
<p>Var(X) = c/λ<sup>2</sup>.</p>
<p>Let C and L denote our estimators of c and λ, to be derived. Replacing population quantities by sample analogs, we set</p>
<p>Ā = C/L</p>
<p>and</p>
<p>S<sup>2</sup> = C/L<sup>2</sup></p>
<p>Dividing the two equations, that gives us</p>
<p>L = Ā / S<sup>2</sup></p>
<p>and</p>
<p>C = L Ā</p>
<p>There are variations. E.g. instead of the variance and sample variance, we can use the <em>second moment</em>, E(X<sup>k</sup>) and its sample analog</p>
<p>(1/n) Σ<sub>i</sub><sup>n</sup>X<sub>i</sub><sup>k</sup></p>
<p>This may be easier if, say, we have 3 parameters to estimate.</p>
<p><strong>The method of maximum likelihood</strong></p>
<p>Discrete case:</p>
<blockquote class="blockquote">
<p>Say we model the population as having a probability mass function p<sub>X</sub> that depends on some (scalar or vector) parameter θ. Calculate the probability (i.e.&nbsp;“likelihood”) of our observed data, as a function of θ. Replace θ by T everywhere in that expression; and finally, then take the MLE to be whatever value of T maximizes that likelihood.</p>
</blockquote>
<p>If our X<sub>i</sub> are independent, then the likelihood expression is</p>
<p>Π<sub>i</sub><sup>n</sup> p(X<sub>i</sub>)</p>
<p>We usually maximize the logarithm, to make derivatives easier.</p>
<p>Continuous case:</p>
<p>A density function is not a probability – it can be larger than 1 – but it does work roughly as a likelihood; if say f(12.3) is large, then one will see many X that are near 12.3. So, in the above prescription, replace p by f.</p>
<p>For instance, consider the family of exponential distributions, f<sub>X</sub>(t) = λ exp(-λt), t &gt; 0. The likelihood is</p>
<p>Π<sub>1</sub><sup>n</sup> [λ exp(-λX<sub>i</sub>)]</p>
<p>with log likelihood</p>
<p>n log(λ) - λ ∑<sub>i</sub><sup>n</sup> X<sub>i</sub></p>
<p>Setting the derivative to 0, we have</p>
<p>n/λ = ∑<sub>i</sub><sup>n</sup> X<sub>i</sub></p>
<p>so that the MLE is 1 / Ā.</p>
<p><em>Non-differentiable case</em></p>
<p>Consider the <em>negative binomial</em> distribution family,</p>
<p>P(X = j) = C(n-1,i-1) r<sup>i</sup> (1-r)<sup>n-i</sup></p>
<p>where C(u,v) means the number of combinations of v objects, chosen from u of them.</p>
<p>This arises, say, from tossing a coin until we accumulate k heads, with r being the probability of heads.</p>
<p>If our parameter to be estimated is r, with known k, the above is a differentiable function of r. But if we don’t know k, say we have the data but did not collect it ourselves, then we don’t have differentiability in that parameter. <em>Ad hoc</em> methods must then be used to find the MLE.</p>
<p><em>Asymptotic normality:</em></p>
<p>We mentioned earlier that the CLT not only applies to sums but also extends to smooth (i.e.&nbsp;differentiable) functions of sums. That fact is important here. How does that play out with MMEs and MLEs?</p>
<p>MMEs: By definition, we are working with sums!</p>
<p>MLE: The log-likelihood is a sum!</p>
<p>So, MMEs and MLEs are generally asymptotically normal, with calculable standard errors.</p>
<p><em>R <strong>mle()</strong> function:</em></p>
<p>This function will calculate MLEs and give standard errors, in smooth cases.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(stats4)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># generate example data from an exponential distribution </span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> x <span class="ot">&lt;-</span> <span class="fu">rexp</span>(n,<span class="dv">2</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> ll  <span class="co"># user supplies the negative log likelihood function</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="cf">function</span>(lamb) {</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>   loglik <span class="ot">&lt;-</span> n<span class="sc">*</span><span class="fu">log</span>(lamb) <span class="sc">-</span> lamb<span class="sc">*</span><span class="fu">sum</span>(x)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>   <span class="sc">-</span>loglik</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># iterative calculation; user here says try 1.0 as the initial guess</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> z <span class="ot">&lt;-</span> <span class="fu">mle</span>(<span class="at">minuslogl=</span>ll,<span class="at">start=</span><span class="fu">list</span>(<span class="at">lamb=</span><span class="dv">1</span>))</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(z)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>maximum likelihood estimation</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>call<span class="sc">:</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="fu">mle</span>(<span class="at">minuslogl =</span> ll, <span class="at">start =</span> <span class="fu">list</span>(<span class="at">lamb =</span> <span class="dv">1</span>))</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>coefficients<span class="sc">:</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>     estimate std. error</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>lamb    <span class="fl">2.195</span>     <span class="fl">0.2195</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span> log l<span class="sc">:</span> <span class="fl">42.76</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Extent of usage:</em></p>
<p>MLEs have appealing theoretical properties. In smooth settings, they are optimal, i.e.&nbsp;minimal standard error. They are quite widely used.</p>
<p>MMs are less popular. But they are easier to explain, and by the way, the inventor of the generalized method of moments won the Nobel Prize in Econoomics in 2013 that developing that method.</p>
</section>
<section id="lesson-estdistrs-estimating-entire-distributions" class="level1">
<h1>Lesson ESTDISTRS: estimating entire distributions</h1>
<p>Recall the <em>cumulative distribution function</em>` (cdf) of a random variable</p>
<p>f<sub>X</sub>(t) = P(X ≤ t)</p>
<p>This is indeed a function; for different values of t, we get different values of the cdf.</p>
<p>And as always, there are population and sample estimates. If X is human height, then F<sub>X</sub>(66.5) is the population proportion of people with height at most 66.5 inches; the sample estimate of that quantity is the corresponding sample proportion.</p>
<p>The entire sample estimate of F<sub>X</sub> is called the <em>empirical cdf</em> (ECDF). Let’s plot it for the geyser data we saw in an earlier lesson.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">ecdf</span>(erps))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="FaithfulCDF.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<p>Since the ECDF consists of proportions (one for each t), it is unbiased. For each t, E[ECDF(t)] =F<sub>X&lt;/sub(t).</sub></p>
<p>We next turn to estimating density functions. We will spend quite a bit of time on this topic, as it illustrates key points that extend to statistics in general.</p>
</section>
<section id="lesson-dens1-estimating-probability-density-functionshistograms" class="level1">
<h1>Lesson DENS1: estimating probability density functions–histograms</h1>
<p>What about estimating the probability density function (pdf)? As noted in Lesson NORMALETC, pdfs do not really exist in practice. Technically, all random variables in real life are discrete rather than continuous, e.g.&nbsp;because of the finite precision of our measuring instruments.</p>
<p>Thus phrasing like “the” pdf above really means the pdf that best approximates the true population distribution. But from here on, let’s just speak of estimating “the” pdf.</p>
<p><strong>Histograms are pdf estimators:</strong></p>
<p>Actually, the familiar histogram is a pdf estimator, provided we specify that the total area under it is 1.0. Here’s why:</p>
<p>First, consider a histogram for the geyser data:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(erps,<span class="at">probability=</span><span class="cn">TRUE</span>)  <span class="co"># second argument indicates area = 1.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="HistErps.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<p>Histograms involve partitioning the range of the data into a certain number of bins (which can be specified with the <strong>breaks</strong> argument in <strong>hist()</strong>).</p>
<p>Let’s look a little closer:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> u <span class="ot">&lt;-</span> <span class="fu">hist</span>(erps,<span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> u</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>breaks</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">1.5</span> <span class="fl">2.0</span> <span class="fl">2.5</span> <span class="fl">3.0</span> <span class="fl">3.5</span> <span class="fl">4.0</span> <span class="fl">4.5</span> <span class="fl">5.0</span> <span class="fl">5.5</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>counts</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">55</span> <span class="dv">37</span>  <span class="dv">5</span>  <span class="dv">9</span> <span class="dv">34</span> <span class="dv">75</span> <span class="dv">54</span>  <span class="dv">3</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here <strong>hist()</strong> gave us the default bin boundaries for this data, at 1.5, 2.0, 2.5 and so on. We see that for instance 37 values of the <strong>erps</strong> fell into the interval from 2.0 to 2.5. This 37 figure was then used to determine the height of the plot for this interval. Why?</p>
<p>Recall that the pdf of X, denoted by f<sub>X</sub>, is the derivative of the cdf F<sub>X</sub>. Recall too that a derivative is the slope of the tangent line to a curve. This in turn is a limit of slopes of line segments (<em>secant lines</em>) between two points on the curve.</p>
<p>Here is an illustration. We drew the N(0,0.5) cdf, and then the tangent line at x = 0.5, as well as the secant line from x = 0.5 to x = 1.0.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="TangentSecant.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<p>Here is the code:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span>(<span class="fu">pnorm</span>(x,<span class="dv">0</span>,<span class="fl">0.5</span>),<span class="sc">-</span><span class="fl">2.5</span>,<span class="fl">2.5</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># draw secant line from x = 0.5 to x = 1</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>point1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fu">pnorm</span>(<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="fl">0.5</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>point2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.0</span>,<span class="fu">pnorm</span>(<span class="fl">1.0</span>,<span class="dv">0</span>,<span class="fl">0.5</span>))</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>point12 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(point1,point2)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(point12[,<span class="dv">1</span>],point12[,<span class="dv">2</span>])</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># abline() slope s at (q,r)</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>abscd <span class="ot">&lt;-</span> <span class="cf">function</span>(q,r,s) <span class="fu">abline</span>(r<span class="sc">-</span>s<span class="sc">*</span>q,s)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abscd</span>(<span class="fl">0.5</span>,<span class="fu">pnorm</span>(<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="fl">0.5</span>),<span class="fu">dnorm</span>(<span class="fl">0.5</span>,<span class="dv">0</span>,<span class="fl">0.5</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As you can see, the secant slope is considerably less than the tangent slope. But if we were to draw the secant from x = 0.5 to say, x = 0.6, the tangent and secant slopes would be more similar.</p>
<p>So, for an interval <strong>(a,b)</strong>, with b-a small,</p>
<p>f<sub>X</sub>(a) ≈ [F<sub>X</sub>(b) - F<sub>X</sub>(a)] / (b-a)</p>
<p>F<sub>X</sub>(b) - F<sub>X</sub>(a) is the probability that X is in <strong>(a,b]</strong>, which we can estimate from the data, say for <strong>a</strong> = 2.0 and <strong>b</strong> = 2.5:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">sum</span>(<span class="fl">2.0</span> <span class="sc">&lt;</span> erps <span class="sc">&amp;</span> erps <span class="sc">&lt;=</span> <span class="fl">2.5</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">37</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">sum</span>(<span class="fl">2.0</span> <span class="sc">&lt;</span> erps <span class="sc">&amp;</span> erps <span class="sc">&lt;=</span> <span class="fl">2.5</span>) <span class="sc">/</span> <span class="fu">length</span>(erps)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.1360294</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Here (b-a) = 2.5 - 2.0 = 0.5. So,</p>
<p>f<sub>X</sub>(2.0) ≈ 0.1360294 / 0.5 = 0.2720588</p>
<p>So, it makes sense that our histogram, viewed as a density estimate, used that 37 <strong>counts</strong> value. The rest, i.e.&nbsp;dividing by the total number of data points 272 times the interval width 0.5, just enter in to make the total area 1.0, which a density must have. As we saw above, we can request this latter property via the <strong>probability</strong> argument:</p>
<p><strong>It’s only approximate!</strong></p>
<p>Note carefully that the symbol ≈ above stems from two considerations:</p>
<ul>
<li><p>We are approximating a tangent by a secant.</p></li>
<li><p>We are using an estimate of F<sub>X</sub> from our sample data, not the population. We return to this point shortly.</p></li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">hist</span>(erps,<span class="at">probability=</span><span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>But we’re not done. Why have an interval width (<em>bin width</em>) of 0.5? It came as the <strong>hist()</strong> default (which actually set the number of intervals). Maybe the intervals should be shorter? Longer? We have this tradeoff:</p>
<ul>
<li><p>If we make b-a too small, we won’t have enough data to get a good estimate.</p></li>
<li><p>If we make b-a too large, then the approximation</p>
<p>f<sub>X</sub>(a) ≈ [F<sub>X</sub>(b) - F<sub>X</sub>(a)] / (b-a)</p>
<p>will not be accurate.</p></li>
</ul>
<p>We will return to this point later, in Lesson TRADE.</p>
<p>Keeping this approximate nature in mind, it is interesting to note that our histogram here is bimodal, i.e.&nbsp;has two peaks. There have been many geophysical theories on this, e.g.&nbsp;postulating that there are two kinds of eruptions.</p>
<p>Histograms are considered rather crude estimators of a density, as they are so choppy. A more advanced approach is that of <em>kernel</em> density estimators.</p>
<p>In estimating the density at a given point t, kernel estimators work by placing more weight on the data points that are closer to t, with the weights being smooth functions of the distance to t. A smooth curve results.</p>
<p>But what does “close” mean? Just as histograms have a <em>tuning parameter</em> (called a <em>hyperparameter</em> in machine learning circles) in the form of the bin width, kernel estimators have something called the <em>bandwidth</em>. Let’s not go into the formula here, but the point is that smaller bandwidths yield a more peaked graph, while larger values produce flatter curves.</p>
<p>Here are the graphs for bandwidths of 0.25 and 0.75:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(erps,<span class="at">bw=</span><span class="fl">0.25</span>))</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(erps,<span class="at">bw=</span><span class="fl">0.75</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DensErps025.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="DensErps075.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<p>The first graph seems to clearly show 2 bells, but the second one is rather ambiguous. With even larger values for the bandwidth (try it yourself), we see a single bell, no hint of 2.</p>
<p>How should we choose the bandwidth, or for that matter, the bin width? if we make the bandwidth too large, some important “bumps” may not be visible. On the other hand, if we make it too small, this will just expose sampling variability, thus displaying “false” bumps.</p>
<p>We’ll address this (but unfortunately not answer it) next.</p>
</section>
<section id="lesson-trade-the-bias-variance-tradeoff" class="level1">
<h1>Lesson TRADE: the Bias-Variance Tradeoff</h1>
<p>In the above histogram of the <strong>erps</strong> data, the graph seems, for example, to be increasing from 2.5 to 4.5. Consider in particular the bin from 3.5 to 4.</p>
<p>The increasing nature of the histogram in that region suggests that the true population density curve f(t) is also rising from 2.5 to 4.5, and in particular, from 3.5 to 4. Yet the histogram height is a constant from 3.5 to 4. This likely would mean that the true f(t) curve is higher than the histogram for t near 4, and lower than the histogram for t near 3.5. In other words:</p>
<blockquote class="blockquote">
<p>The histogram, as an estimate of f, is likely biased upward (i.e.&nbsp; bias &gt; 0) near 3.5 and downward (&lt; 0) near 4.</p>
</blockquote>
<p>And what if the bin width were much narrower? Then the bias described above would still exist, but would be smaller. On the other hand, the narrower the bin, the fewer the number of data points in each bin, so the greater the standard error of the histogram height within a bin. (Roughly speaking, the “n” for the standard error is the number of points in the bin.)</p>
<p>In other words:</p>
<blockquote class="blockquote">
<p>There is a tradeoff here: smaller bins produce smaller bias but larger variance (and the opposite for larger bins).</p>
</blockquote>
<p>So, even though bias was seen not to be an issue in the context of CIs, it <em>is</em> an issue here.</p>
<p>There is no good, universally agreed-to way to choose the bin size. Various math stat people have done some theoretical work that has led to suggestions which you can try, such as setting <strong>breaks=‘fd’</strong> in your call to <strong>hist()</strong>.</p>
<p>Where the Bias-Variance Tradeoff really becomes an isssue is in prediction/machine learning contexts, to be covered later.</p>
</section>
<section id="lesson-multi-multivariate-distributions" class="level1">
<h1>Lesson MULTI: Multivariate Distributions</h1>
<p>Say we have continuous random variables X and Y. We of course can talk about their density functions f<sub>X</sub> and f<sub>Y</sub>, but it’s also important to talk about how they vary (or not) <em>together</em>. First, the basics:</p>
<ul>
<li><p>f<sub>X,Y</sub>(u,v) = ∂/∂u ∂/∂v F<sub>X,Y</sub>(u,v) = P(x ≤u and y ≤v)</p></li>
<li><p>P((x,y) in A) = ∫ ∫<sub>A</sub> f<sub>X,Y</sub>(u,v) du dv</p></li>
<li><p>f<sub>Y | X = v</sub>(u) = f<sub>X,Y</sub>(u,v) / f<sub>X</sub>(u)</p></li>
</ul>
</section>
<section id="lesson-corr-correlation" class="level1">
<h1>Lesson CORR: Correlation</h1>
<p>One common measure of the relation between variables U and V is their (Pearson) <em>correlation</em>, E(U - EU)`(V - EV)] / sqrt[Var(U) Var(V)]. They need not be normal. This is a quantity in [-1,1], often denoted by ρ.</p>
<p>One useful interpretation of correlation is that ρ<sup>2</sup>(U,V) is the proportional reduction in Mean Squared Error in predicting V. Here we are comparing predicting V with and without using U. In the latter case, our prediction for V is EV; in the former case, its E(V | U).</p>
<p>If we are analyzing a group of variables X<sub>i</sub>, i = 1,…,p, their <em>correlation matrix</em> is p X p, with the i,j element being ρ(X<sub>i</sub>,X<sub>j</sub>).</p>
<p>The <em>covariance</em> between variables U and V is the same as the correlation, but not standardized by the standard deviations:</p>
<p>Cov(U,V) = E(U - EU)`(V - EV)] = E(UV) - EU EV</p>
<p>The <em>covariance matrix</em> is defined accordingly.</p>
<p>Note that covariance is bilinear and unaffected by additive constants. E.g.</p>
<p>Cov(aU+b,cV+d) = ac Cov(U,V)</p>
<p>Note that if U and V are independent, then E(UV) = EU EV, so the covariance and correlation are 0. The converse is not true; 0 covariance and correlation do <em>not</em> imply independence.</p>
</section>
<section id="lesson-mvn-the-multivariate-normal-distribution-family" class="level1">
<h1>Lesson MVN: The Multivariate Normal Distribution Family</h1>
<p>Unlike the univariate case, there are very few widely-used parametric families of multivariate distributions. The main one is multivariate normal.</p>
<p>The MV normal family does have some interesting properties, though:</p>
<pre><code>- all marginal distributions are MV normal

- AX is MV normal for MV normal X and constant matrix A

- conditional distributions, given a singleton value, are MV normal

- those conditional distributions have mean that is linear in the
  conditioning value, and variance (or covariance matrix) that does
  not depend on that value</code></pre>
</section>
<section id="lesson-predict-predictive-modeling-preliminaries" class="level1">
<h1>Lesson PREDICT: Predictive Modeling – Preliminaries</h1>
<p>From the 19th century linear models to today’s fancy machine learning (ML) algorithms, a major application of statistics has been prediction. In this lesson, we set the stage for discussing prediction.</p>
<p>Say we are predicting a scalar Y from (a typically vector-valued) X. Let p(X) denote our prediction. Classically, we wish to minimize the mean squared prediction error,</p>
<p>E[(Y - p(X))<sup>2</sup>]</p>
<p>Note that E() will be the average over all possible (X,Y) pairs in the population. Other loss functions besides squared-error are possible, but this one is mathematically tractable.</p>
<p>The minimizer is easily shown to be</p>
<p>p(X) = E(Y | X)</p>
<p>Note that in the case of Y being an indicator variable, this reduces to</p>
<p>p(X) = P(Y = 1 | X)</p>
<p>Borrowing from the fact that a typical symbol for the mean is μ, let’s define the function</p>
<p>μ(t) = E(Y | X = t)</p>
<p>which, as noted, in the case of dichotomous Y becomes</p>
<p>μ(t) = P(y = 1 | X = t)</p>
<p>This is called the <em>regression function of Y on X</em>. Note that this is a general term, not restricted just to the linear model.</p>
<p>Our goal, then, is to use our sample data</p>
<p>(X<sub>1</sub>,Y<sub>1</sub>),… (X<sub>n</sub>,Y<sub>n</sub>)</p>
<p>to estimate μ(t). Denote the sample estimate by m(t). To predict a new case, X<sub>new</sub>, we use m(X<sub>new</sub>). Keep in mind, m(t) is an estimate of an entire function here, one value for each t.</p>
<p>We will often take as a convenient example predicting weight Y from height X, or a vector X = (height,age).</p>
<p>The Bias-Variance Tradeoff becomes key in such models. The more predictors we use (<em>features</em> in ML parlance), the smaller the bias in m(t) but the larger the variance. If we keep adding features, at some point the variance becomes dominant, and we overfit.</p>
</section>
<section id="lesson-mlb-the-mlb-dataset" class="level1">
<h1>Lesson MLB: the MLB Dataset</h1>
<p>This data, on major league baseball players in the US, is included with my <a href="github.com/matloff/qeML"><strong>qeML</strong> package</a> (“quick ML”).</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">head</span>(mlb)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>        position height weight   age</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>        catcher     <span class="dv">74</span>    <span class="dv">180</span> <span class="fl">22.99</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span>        catcher     <span class="dv">74</span>    <span class="dv">215</span> <span class="fl">34.69</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span>        catcher     <span class="dv">72</span>    <span class="dv">210</span> <span class="fl">30.78</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>  first_baseman     <span class="dv">72</span>    <span class="dv">210</span> <span class="fl">35.43</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span>  first_baseman     <span class="dv">73</span>    <span class="dv">188</span> <span class="fl">35.71</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We’ll usually use just height, weight and age.</p>
</section>
<section id="lesson-lin-predictive-modeling-linear" class="level1">
<h1>Lesson LIN: Predictive Modeling – Linear</h1>
<p>As noted, if (X,Y) has a multivariate normal distribution (say with Y scalar and X vector), then the following attributes hold:</p>
<ul>
<li><p>linearity of the regresion function: μ(t) is linear in t</p></li>
<li><p>conditional normality of Y given X = t</p></li>
<li><p>conditional homogeneous variance: Var(Y | X = t) is constant in t</p></li>
</ul>
<p>These traits led to the classical <em>linear regression model</em>: One assumes that</p>
<p>μ(t) = β<sub>0</sub> + β<sub>1</sub> t<sub>1</sub> + … β<sub>p</sub> t<sub>p</sub></p>
<p>for a p-predictor model, where t = (t<sub></sub>,…,t<sub>p</sub>)‘, a column vector;’ means matrix transpose and the default for vectors is column form.</p>
<p>In vector form, our assumption is</p>
<p>μ(t) = (1,t)’ β</p>
<p>where β and (1,t) are taken to be column vectors. Note the presence of the 1, which is needed to pick up the β<sub>0</sub> term.</p>
<p>Again, the β<sub>i</sub> are population values.</p>
<p>One also assumes homogeneous variance as above, and of course independent observations (X<sub>i</sub>,Y<sub>i</sub>). Note thath the X<sub>i</sub> are vectors of length p.&nbsp;If say we are predicting weight from height and age, then X<sub>i</sub> is the vector whose components are the height and age of the i<sup>th</sup> person in our sample data.</p>
<p>The sample estimates vector b is computed by minimizing</p>
<p>Σ<sub>1</sub><sup>n</sup> [Y<sub>i</sub> - (1,X<sub>i</sub>)’ b]<sup>2</sup></p>
<p>A closed-form solution exists, and is implemented in r as <strong>lm()</strong>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> z <span class="ot">&lt;-</span> <span class="fu">lm</span>(weight <span class="sc">~</span> height<span class="sc">+</span>age,<span class="at">data=</span>mlb)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">summary</span>(z)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>call<span class="sc">:</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(<span class="at">formula =</span> weight <span class="sc">~</span> height <span class="sc">+</span> age, <span class="at">data =</span> mlb)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>residuals<span class="sc">:</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>    min      <span class="dv">1</span>q  median      <span class="dv">3</span>q     max </span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="fl">50.535</span> <span class="sc">-</span><span class="fl">12.297</span>  <span class="sc">-</span><span class="fl">0.297</span>  <span class="fl">10.824</span>  <span class="fl">74.300</span> </span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>coefficients<span class="sc">:</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>             estimate std. error t value <span class="fu">pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)    </span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>(intercept) <span class="sc">-</span><span class="fl">187.6382</span>    <span class="fl">17.9447</span>  <span class="sc">-</span><span class="fl">10.46</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>height         <span class="fl">4.9236</span>     <span class="fl">0.2344</span>   <span class="fl">21.00</span>  <span class="sc">&lt;</span> <span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>age            <span class="fl">0.9115</span>     <span class="fl">0.1257</span>    <span class="fl">7.25</span> <span class="fl">8.25e-13</span> <span class="sc">**</span><span class="er">*</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>signif. codes<span class="sc">:</span>  <span class="dv">0</span> ‘<span class="sc">**</span><span class="er">*</span>’ <span class="fl">0.001</span> ‘<span class="sc">**</span>’ <span class="fl">0.01</span> ‘<span class="sc">*</span>’ <span class="fl">0.05</span> ‘.’ <span class="fl">0.1</span> ‘ ’ <span class="dv">1</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Note the standard errors. An approximate 95% confidence interval for β<sub>age</sub> is</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rad <span class="ot">&lt;-</span> <span class="fl">1.96</span><span class="sc">*</span><span class="fl">0.1257</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">c</span>(<span class="fl">0.9115</span> <span class="sc">-</span> rad, <span class="fl">0.9115</span> <span class="sc">+</span> rad)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.665128</span> <span class="fl">1.157872</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Ah, even these professional athletes tend to gain weight as they age, something like a pound per year.</p>
<p><strong>But what about those above classical assumptions for the linear model?</strong> Do they matter?</p>
<p>On the one hand, the answer is “not much.”</p>
<ul>
<li><p>The formula for the least-squares estimator b consists of various sums, so that the Central Limit Theorem tells us that b is approximaely normal even if the conditional normality assumption doesn’t hold.</p></li>
<li><p>Violations of the homogeneous conditional variance assumption can be handled by <em>sandwich estimators</em>, e.g.</p></li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(sandwich)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">vcovhc</span>(z)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>            (intercept)       height          age</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>(intercept) <span class="fl">323.5135765</span> <span class="sc">-</span><span class="fl">4.151528253</span> <span class="sc">-</span><span class="fl">0.629074510</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>height       <span class="sc">-</span><span class="fl">4.1515283</span>  <span class="fl">0.055692865</span>  <span class="fl">0.002166495</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>age          <span class="sc">-</span><span class="fl">0.6290745</span>  <span class="fl">0.002166495</span>  <span class="fl">0.015967653</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>A more accurate standard error for β<sub>age</sub> is thus</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">sqrt</span>(<span class="fl">0.015967653</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.1263632</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>(not much change here, but there is a larger difference in some cases).</p>
<p>Those considerations are important if our goal is <em>understanding</em>, e.g.&nbsp;understanding weight gain in pro ball players.</p>
<p>On the other hand, for the <em>prediction</em> goal, those issues are irrelevant; all that really matters is whether the true μ(t) is approximately linear. (And if it isn’t, we aren’t achieving the understanding goal either; our CIs will be invalid.) That would seem to argue in favor of using ML models, which do not make linearity assumptions.</p>
<p>But there’s more:</p>
<p>One can fit more complex models that are still linear, e.g. a full quadratic model of the regression of weight on height and age,</p>
<p>mean wt = β<sub>0</sub> + β<sub>1</sub> ht + β<sub>2</sub> age + β<sub>3</sub> ht<sup>2</sup> + β<sub>4</sub> age<sup>2</sup> + β<sub>5</sub> ht age</p>
<p>This is still a linear model, as it is linear in β, even though it is nonlinear in height and age.</p>
<p>We can fit polynomial models using the <a href="https://cran.rstudio.com/web/packages/polyreg/index.html">polyreg</a> package (or use <strong>qeml::qepoly()</strong>). But as we fit polynomials of higher and higher degree, we quickly run into the Bias-Variance Tradeoff. The variance becomes large, i.e.&nbsp;the fitted coefficients will vary a lot from one sample to another, while the reduction in bias slows down. So we risk overfitting.</p>
<p>In that case, a nonparametric model, such as from ML, may work much better. However, keep in mind that ML models can overfit too. More on this shortly.</p>
</section>
<section id="lesson-lmderive-the-math-behind-least-squares-estimation" class="level1">
<h1>Lesson LMDERIVE: The math behind least-squares estimation</h1>
<p>As noted, the sample estimate b of β is obtained by minimizing</p>
<p>Σ<sub>1</sub><sup>n</sup> [Y<sub>i</sub> - (1,X<sub>i</sub>)’ b]<sup>2</sup></p>
<p>In a matrix formulation, that sum of squares is</p>
<p>W = (D - Ab)’ (D - Ab)</p>
<p>where D is the vector of Y values and row i of A is (1,X<sub>i</sub>)’.</p>
<p>We need to find the derivative of this with respect to b. That is the vector of partial derivatives</p>
<p>( ∂W / ∂b<sub>0</sub>, ∂W / ∂b<sub>1</sub>, …, ∂W / ∂b<sub>p</sub> )’</p>
<p>Using simple algebra, it’s easy to show that ∂/∂v (v’v) = 2v. Applying this and the Chain Rule to the above, we have</p>
<p>∂/∂b W = 2A’(D - Ab)</p>
<p>(The order of factors here makes the multiplied matrices conformable.)</p>
</section>
<section id="lesson-logit-predictive-modeling-logistic" class="level1">
<h1>Lesson LOGIT: Predictive Modeling – Logistic</h1>
<p>What about the case in which Y is an indicator variable, say diabetic (Y = 1) vs.&nbsp;nondiabetic (Y = 0)?</p>
<p>Recall that in this setting, μ(t) reduces to P(Y = 1 | X = t). That makes a linear model untenable, as it would produce values outside the [0,1] range for probabilities.</p>
<p>Just as the linear model was originally inspired by multivariate distributions, the same is true for logit. So again let’s start with the classical normal-distribution based model. This is known as <em>Fisher Linear Discriminant Analysis</em> (LDA).</p>
<p>Here, the distribution of X, given that Y = i, is assumed multivariate normal with mean vector ν<sub>i</sub> and covariance matrix c that does not depend on i. Let r denote P(Y = 1) (unconditional).</p>
<p>If one then applies Bayes’ rule (just a probability calculation, not Bayesian statistics), one finds that</p>
<p>P(Y = 1 | X = t)</p>
<p>has a <em>logistic</em> (often nicknamed <em>logit</em>) form: If X we have a single predictor (so ν<sub>i</sub> is a scalar and c is just the standard deviation σ), the form is</p>
<p>P(Y = 1 | X = t) = 1 / [1 + exp(-{ω<sub>0</sub> + ω<sub>1</sub>t)}]</p>
<p>for parameters ω<sub>0</sub> and ω<sub>1</sub> that depend on the v<sub>i</sub> and σ. In the case of multiple features, this is</p>
<p>P(Y = 1 | X = t) = 1 / [1 + exp(-ω’t)]</p>
<p><strong>This probability interpretation of logit is key.</strong></p>
<p>Let’s call the above, “the logistic equation.”</p>
<p>So again: Just as the linear model originally arose in the context of multivariate normal distributions, this was the case for logit as well. But again, as in the case of the linear model discussion above, we must ask, <strong>what if the assumptions, e.g.&nbsp;normality, don’t hold?</strong></p>
<p>And the answer is that the logit model is quite popular anyway, and for good reason: The logistic equation does produce a value in (0,1), which is what we want for a probability of course, yet we still have a linear ingredient ω’t, the next-best thing to a pure linear model.</p>
<p>Moreover, as in the linear case, we can introduce polynomial terms to reduce model bias. (It will turn out below that there is also a “polynomial connection” to some popular ML methods, SVM and neural networks.)</p>
<p>By the way, many books present the logit model in terms of “linear log-odds ratio.” The odds ratio is</p>
<p>P(Y = 1 | X = t) / [P(Y = 0 | X = t)]</p>
<p>While it is true that the log of that quantity is linear in the logit model, this description seems indirect. We might be interested in the odds, but why would the <em>logarithm</em> of the odds be of interest? It’s best to stick to the basics:</p>
<ul>
<li><p>A model for a probability should produce values in (0,1).</p></li>
<li><p>It would be nice if the model has an ingredient the familiar linear form.</p></li>
</ul>
<p>Logit, which we have handy from LDA, satisfies those desiderata.</p>
</section>
<section id="lesson-knn-predictive-modeling-k-nearest-neighbors" class="level1">
<h1>Lesson KNN: Predictive Modeling – k-Nearest Neighbors</h1>
<p>One of the simplest ML methods is k-Nearest Neighbors. Say we are predicting weight from height and age, and must do so for a new case in which X = (70,28). Then we find the k rows in our training data that are closest to (70,28), find the average weight among those data points, and use that average as our predicted value for the new case.</p>
</section>
<section id="lesson-tree-predictive-modeling-tree-based-algorithms" class="level1">
<h1>Lesson TREE: Predictive Modeling – Tree-Based Algorithms</h1>
<p>This ML category is almost as simple to explain. At the root of the tree, we ask whether a given feature is above or below a given threshold, and then go left or right accordingly. At our next node, we ask the same question of another feature, and so on.</p>
<p>Eventually we wind up in a leave. In the continuous Y case, our prediction is the average Y value in the leaf; for categorical Y, our prediction is whichever category is most numerous in the leave.</p>
<p>Here is a picture from using <strong>qeML::qeDT()</strong> on the Census data in <strong>qeML</strong>:</p>
<p>Here we are predicting one of 5 occupations. The picture is too small for this dataset, with all the leaves jumbled together at the bottom, but the process should be clear.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="TreePredOcc.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
</section>
<section id="lesson-svm-predictive-modeling-support-vector-machines" class="level1">
<h1>Lesson SVM: Predictive Modeling – Support Vector Machines</h1>
<p>SVM is used mainly in classification contexts. Here we will assume just two classes, for simplicity.</p>
<p>The idea behind SVM is very simple. think of the case of two features. We can plot the situation as follows. Consider this graph, in the context of predicting diabetes, from blood glucose and age:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="PimaGlucAgeDiab.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<p>The red dots are the diabetics. We would like to draw a line so that most of the red dots are on one side of the line and most of the black ones are on the other side. We then use that line too predict future cases. Of course if we have more than two features the line becomes a plane or hyperplane.</p>
<p>Well, why just limit ourselves to a straight line? Why not make it a quadratic curve, a cubic curve and so on? Each one gives us more flexibility than the last, hence a potentially better fit.</p>
<p>That is exactly what SVM methods do, apply a transformation (a <em>kernel</em>) to the features, and then find a straight line separating the transformed data. This is equivalent to forming a curvy line in the original X space. There are many common choices of kernels, including polynomials.</p>
</section>
<section id="lesson-neural-predictive-modeling-neural-networks" class="level1">
<h1>Lesson NEURAL: Predictive Modeling – Neural Networks</h1>
<p>In a neural network (NN), , we have a set of layers. Think of them as being arranged from left to right. The input data goes in on the left side and the predicted values come out on the right side. the output of each layer gets fed in as input to the next layer, being fed through some transformation (an <em>activation function</em>). At each layer, in essence the input is sent through a linear regression estimation, with the result then passed on to the next layer.</p>
<p>A layer consists of a number of <em>units</em>. Every output of one layer is fed into each unit of the next layer. So the number of units per layer, and the number of layers, are hyperparameters.</p>
</section>
<section id="lesson-nbhr-predictive-modeling-a-feature-neighborhood-view-of-overfitting-in-ml" class="level1">
<h1>Lesson NBHR: Predictive Modeling – a Feature Neighborhood View of Overfitting in ML</h1>
<p>The Bias-Variance Tradeoff with k-NN is clear (and similar to the density estimation example above). If k is large, the neighborhood of (70,28) will be large, and thus will contain some unrepresentative points that are far from (70,28). If k is small, the sample mean in our neighborhood will have a large standard error, as its “n” (k here) is small.</p>
<p>The situation is similar for tree-based methods (CART, random forests, gradient boosting). As we move down a tree, we add more and more features to our collection, and the nodes have less and less data. For a fixed amount of data, the more levels in the tree, the fewer data points in each of the leaves. Since the leaves are similar to neighborhoods in k-NN, we see the same Bias-Variance Tradeoff.</p>
</section>
<section id="lesson-polyml-predictive-modeling-a-polynomial-view-of-overfitting-in-ml" class="level1">
<h1>Lesson POLYML: Predictive Modeling – a Polynomial View of Overfitting in ML</h1>
<p>In Lesson LIN, We discussed overfitting in the context of polynomial regression. Here polynomials will give us a look into how ML algorithms can also overfit, specifically in support vector machines (SVM) and neural networks (NNs).</p>
<p>Clearly we can have a situation in which the dividing line in SVM may get so curvy that it “fits the noise rather than the data,” as they say. There is a true population curve, consisting of all the points t for which μ(t) = 0.5, and the curvier we allow our fit, the smaller the bias. But as in the linear case, the curvier the fit, the larger the variance. The fitted curve varies too much from one sample to another.</p>
<p>And though we motivated the above discussion by using polynomial curves, just about any common kernel function can be approximated by polynomials. The principle is the same.</p>
<p>For NNs, suppose the activation function is a(t) = t<sup>2</sup>. This is not a common choice at all, but it will make the point. The output of the first layer in our example here is a linear combination of the glucose and age features. The activation function squares that, giving us a quadratic polynomial in glucose and age. After the second stage, we will have a quartic (i.e.&nbsp;fourth degree) polynomial and so on.</p>
<p>So basically we are doing a lot of linear regression fits and as this goes from layer to layer, they gets multiplied. You’re basically building up polynomials of higher and higher degree.</p>
<p>And again, almost any activation function can be approximated by a polynomial, so the same argument holds. So again it’s clear how easily we can run into overfitting.</p>
<p>A very common activation function today is reLU, which is piecewise linear: a(t) = t for t &gt; 0, but = 0 for t &lt; 0. After several layers, this has the effect of partitioning the X space like a patchwork quilt, except that the “patches” are of irregular shape. Well, again: The more layers we have, the smaller the “patches,” i.e.&nbsp;the smaller the neighborhoods. So the situation is just like that of k-NN etc.</p>
</section>
<section id="lesson-over-predictive-modeling-avoiding-overfitting" class="level1">
<h1>Lesson OVER: Predictive Modeling – Avoiding Overfitting</h1>
<p>How can we try to avoid overfitting?</p>
<ul>
<li><p>Most regression models, both parametric and ML, have <em>regularized</em> versions: to guard against extreme data having too much impact, predicted values are shrunken toward 0 in some manner. In the linear case, we have <em>ridge regression</em> and the LASSO, which work by shrinking b, the estimated β vector. Regularized versions of SVM, NNs etc. also exist.</p></li>
<li><p>We can do <em>dimension reduction</em> by mapping our features into a lower-dimensional subspace, e.g.&nbsp;via Principal Components Analysis or UMAP.</p></li>
<li><p>We can do <em>cross validation</em>: Take many subsamples of the data (i.e. a subset of the rows). In each one fit our model to the subsample and use the result to predict the remaining data. In this way, choose among competing models.</p></li>
</ul>
</section>
<section id="lesson-noworry-predictive-modeling-ignoring-overfitting" class="level1">
<h1>Lesson NOWORRY: Predictive Modeling – Ignoring Overfitting</h1>
<p>Some people take a very different point of view: in some settings, we can overfit and not worry about it. A common claim is “ML models drastically overfit, yet predict new cases very well.”</p>
<p>This is misleading, in my opinion. In the celebrated ML successes, the misclasification rate is very small, even without hyperparameter tuning. in the SVM sense, this means that the two classes are almost completely separable after transformation of X. Thus <strong>many different straight lines or hyperplanes can achieve the separation,</strong> which means that back in the original X space, there are many separating curves, including some of very high complexity. In other words, due to the separability of the data, we can get away with overfitting.</p>
<p>Here is an example, using a famous image recognition dataset (generated by code available <a href="https://jlmelville.github.io/uwot/metric-learning.html">here</a>:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="UMAPFMNIST.png" class="img-fluid figure-img"></p>
<figcaption>alt text</figcaption>
</figure>
</div>
<p>There are 10 classes, each shown in a different color. Here the SNE method (think of it as a nonlinear PCA) was applied for dimension reduction, dimension 2 here. There are some isolated points here and there, but almost all the data is separated into 10 “islands.” Between any 2 islands, there are tons of high-dimensonal curves, say high-degree polynomials, that one can fit to separate them. So we see that overfitting is just not an issue, even with high-degree polynomials.</p>
</section>
<section id="lesson-privacy-data-privacy" class="level1">
<h1>Lesson PRIVACY: Data Privacy</h1>
<p>Consider a database of medical records, intended for research purposes but in which privacy of individual patient records is paramount. The privacy and research goals are at odds with each other. How can we achieve both goals to an acceptable degree? This is the <em>data privacy</em> or <em>statistical disclosure control</em> problem.</p>
<p><strong>Clearly there is no perfect system</strong>, achieving both goals perfectly. Instead, we must settle for aiming for just a degree of privacy, with higher degrees affording great protection from intruders but less accuracy for researchers, and vice versa: less privacy protection for greater access for researchers.</p>
<p><strong>Overview</strong></p>
<p>This is a vast, highly technical field, so I will just give an overview of some of the issues. Here are a few common approaches:</p>
<ul>
<li><p>Random noise addition. To hide, say, the income of a person in the database, we might add mean-0 random noise, say of standard deviation σ. The larger the value of σ, the less the intruder knows about the person’s true income. On the other hand, large values of σ cause larger standard errors in statistical estimators, thus hinder researchers.</p></li>
<li><p>Data swapping: A percentage p of all records will have some sensitive attributes swapped with others.</p></li>
<li><p>Cell suppression: Say our data consists of r categorical variables (or can be discretized). This produces an r-way table. The method then bars release of any cell with a count of below w.</p></li>
<li><p>k-anonymity: The data is modified in such a way that for any person in the database, at least k-1 others in the database share the same sensitive attributes as the given person.</p></li>
<li><p>Differential privacy (DP): For any statistical quantity, say the mean, median, linear regression model etc., the data is modified so that there is a controllably low probability that the quantity would change much if a given record were removed from the database. Methods using DP as a privacy measure typically involve some DP-specific form of noise addition. There is a hyperparameter ε.</p>
<p>A different method must be devised for each kind of statistic, such as one for means, one for medians, one for linear regression analysis, and so on. This limits the kinds of analyses open to researchers, as they can only use methods that have been developed and installed in the given database.</p></li>
</ul>
<p><strong>Risk-Utility Tradeoff</strong></p>
<p>Note that noise addition is a <em>method</em> for achieving privacy and σ is a <em>measure</em> of the degree of privacy protection. With data swapping, we again have both a method and a measure (p), and similarly with cell supppression, where the measure is w.</p>
<p>But in the k-anonymity and DP examples, k and ε are only privacy <em>measures</em>, and do not specify methods top achieve the given levels of privacy.</p>
<p>In all examples, though, there is what we will call the Risk-Utility Tradeoff: The lesser the degree of risk, the less the accuracy, and vice versa. With cell suppression, for instance, a small value of w gives better access for researchers, but has a greater risk of disclosure of private information.</p>
<p><strong>Statistical issues</strong></p>
<p>Note that privacy measures based on probabilistic considerations involve only the privacy mechanism itself, rather than reflecting sampling error, key to statistical analysis. Pure noise addition, for instance, adds further variance, beyond that arising via sampling variation.</p>
<p>And even more concerning, privacy mechanisms add bias. Consider noise addition, for example. Say we add independent 0-mean noise variables ε<sub>1</sub> and ε<sub>2</sub> to U and V. That increases Var(U) and Var(V) in the denominator of ρ(U,V), while in the numerator</p>
<p>E[(U+ ε<sub>1</sub>)(V+ ε<sub>2</sub>)] = E(UV),</p>
<p>E[(U+ ε<sub>1</sub>)] = E(U)</p>
<p>E[(V+ ε<sub>2</sub>)] = E(V)</p>
<p>In other words, the numerator of ρ(U,V) is unchanged but the denominator increases. So, |ρ(U,V)| is reduced, i.e.&nbsp;the relation between U and V has been weakened. This of course is a very serious problem, since the researchers are usually studying relations between variables.</p>
<p>With simple noise addition, there is a simple remedy: Make ε<sub>1</sub> and ε<sub>2</sub> correlated, with the correlation structure as U and V. But for other DP methods and measures, things are much less simple.</p>
<p><strong>Rejected queries</strong></p>
<p>In the cell suppression method, we reject queries that involve too few records and are thus more vulnerable to disclosure. Some other methods may also involve some kind of cell suppression. For instance, <a href="https://arxiv.org/pdf/2004.04145.pdf">Google’s Covid-19 mobility data</a> exclude cell counts of less than 100.</p>
<p>In addition to the correlation attenuation issue, i.e.&nbsp;weakened Utility, another problem with cell suppression is a potential increase in Risk. A set of cleverly-designed queries, seemingly inoccuous, can lead to <a href="https://www.fcsm.gov/assets/files/docs/2009FCSM_Cox_III-A.pdf">information disclosure</a>.</p>
<p><strong>DP issues</strong></p>
<p>DP has been the subject of much <a href="https://www.bloomberg.com/news/articles/2021-08-12/data-scientists-ask-can-we-trust-the-2020-census">controversy</a>. It was heavily promoted in the computer science community, and has many devoted adherents there. On the other hand, some applied researchers have strenuously questioned its usefulness in practice.</p>
<p>Again, there is no perfect privacy system. I disagree with those who promote DP as “the” solution to the privacy problem. After all, even they concede that DP is vulnerable to certain kinds of database attacks, and has various other drawbacks. It should thus be clear: A privacy specialist should have broad knowledge of the concepts and methods in the general privacy field, and should not rely solely on any particular one.</p>
</section>
<section id="licensing" class="level1">
<h1>LICENSING</h1>
<p>The document is covered by a <a href="http://creativecommons.org/licenses/by-nd/3.0/us/">creative commons</a> license, creative commons attribution-no derivative works 3.0 united states <img src="http://i.creativecommons.org/l/by-nd/3.0/us/88x31.png" class="img-fluid" alt="alt text">. I have written the document to be <em>used</em>, so readers, teachers and so on are very welcome and encouraged to copy it verbatim. Copyright is retained by n.&nbsp;matloff in all non-u.s. jurisdictions, but permission to use these materials in teaching is still granted, provided the authorship and licensing information here is displayed. I would appreciate being notified if you use this book for teaching, just so that i know the materials are being put to use, but this is not required. Information displayed. No warranties are given or implied for this material.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>